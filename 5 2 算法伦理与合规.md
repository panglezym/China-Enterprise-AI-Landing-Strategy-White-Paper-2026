# 5.2 算法伦理与合规

上级 项目: 5.0第五章： 风险与治理——悬在头顶的达摩克利斯之剑  (5%200%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%20%E9%A3%8E%E9%99%A9%E4%B8%8E%E6%B2%BB%E7%90%86%E2%80%94%E2%80%94%E6%82%AC%E5%9C%A8%E5%A4%B4%E9%A1%B6%E7%9A%84%E8%BE%BE%E6%91%A9%E5%85%8B%E5%88%A9%E6%96%AF%E4%B9%8B%E5%89%91%202d59dae32cda80be9033f3ef97641d80.md)
状态: 完成
结束时间: 2025年11月29日

如果不加控制，企业 AI 就是一个“喝醉酒的博士”：知识渊博，但随时可能胡言乱语，甚至口出狂言（种族歧视、性别偏见）。

在 2026 年，**可信 AI（Trustworthy AI）** 的建设标准不再是“准确率”，而是“可控性”。

### **5.2.1 治愈幻觉：基于证据的生成（Grounding）**

这是对抗幻觉最有效的手段。我们要求 AI **“从不凭空创作，只做信息搬运”**。

- **引用溯源 (Citations)：** 强制要求 AI 在输出的每一句话后面，标注信息的来源文档。
    - *Bad:* “公司去年的营收增长了 20%。”（无来源，可能是瞎编的）
    - *Good:* “公司去年的营收增长了 20% [来源: 2024年年度财报.pdf, Page 15]。”
- **拒答机制 (Refusal Skills)：** 训练模型学会说“我不知道”。 当用户的问题超出了知识库的范围（如“公司明年的股价会是多少？”），AI 必须回答：“抱歉，知识库中没有相关信息”，而不是编造一个数字。

### **5.2.2 过滤偏见：内容安全护栏 (Content Safety Guardrails)**

企业 AI 代表了品牌形象。如果 AI 输出了带有歧视性、暴力或政治敏感的内容，将引发公关灾难。

我们需要在模型输出端架设一道“内容防火墙”。

- **输入端过滤：** 如果用户问“怎么制造毒药？”，护栏层直接拦截，不发送给大模型。
- **输出端过滤：** 大模型生成回复后，护栏层进行二次扫描。如果检测到“脏话”或“敏感词”，立即替换为兜底话术。
- **价值观对齐 (Alignment)：** 在微调阶段，使用 **RLHF（基于人类反馈的强化学习）** 技术，奖励那些“客观、中立、有礼貌”的回答，惩罚“偏激、攻击性”的回答。

### **5.2.3 自动化评估：AI 考 AI (LLM-as-a-Judge)**

靠人工一条条看聊天记录是不现实的。2025 年的主流做法是建立**自动化评估管线**。

我们引入一个更强的大模型（如 GPT-4 或文心 4.0）作为“考官”，来给业务小模型的回答打分。

- **真实性 (Faithfulness)：** 回答是否忠实于检索到的文档？有没有添油加醋？
- **相关性 (Relevance)：** 回答是否解决了用户的问题？
- **毒性 (Toxicity)：** 回答是否包含有害内容？

**【代码示例：构建一个简单的“幻觉检测器”】** *以下代码展示了如何利用大模型自我反思，来检查一段回答是否存在幻觉。*

Python

`def hallucination_check(context, answer):
    """
    使用大模型作为裁判，判断 Answer 是否由 Context 推导而来
    """
    prompt = f"""
    [任务]
    请判断以下的 [回答] 是否完全基于 [参考文档] 生成。
    如果在文档中找不到依据，请判定为"有幻觉"。
    
    [参考文档]
    {context}
    
    [回答]
    {answer}
    
    [输出要求]
    仅输出 JSON 格式：{{"is_hallucinated": true/false, "reason": "理由"}}
    """
    
    # 调用高智商模型（如 GPT-4）进行裁决
    evaluation = call_llm(prompt)
    return evaluation

# 模拟场景
doc = "本公司规定，差旅费报销标准为每日 500 元。"
ai_response = "根据规定，您可以报销每日 800 元的差旅费。"

check_result = hallucination_check(doc, ai_response)
print(check_result)
# 输出: {"is_hallucinated": true, "reason": "文档中规定为500元，回答中却说是800元，数据不一致。"}`

**小结：信任是 AI 落地的货币。** 没有“紧箍咒”的 AI 就像没有刹车的跑车，性能越强，车祸越惨。 企业必须建立 **Grounding（扎根） + Guardrails（护栏） + Evaluation（评估）** 的三位一体防御体系，才能放心地把业务交给 AI。